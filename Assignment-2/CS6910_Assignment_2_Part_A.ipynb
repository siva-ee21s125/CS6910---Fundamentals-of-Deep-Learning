{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z5htegpQaYX8",
        "outputId": "d2aa8e19-b30f-4784-ce9c-961b50deef8e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Extracted the dataset\n"
          ]
        }
      ],
      "source": [
        "#Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "#Load and unzip iNaturalist zip file onto server, then remove zip to optimize performance\n",
        "zip_path = \"drive/MyDrive/nature_12K.zip\"\n",
        "!cp \"{zip_path}\" .\n",
        "!unzip -q nature_12K.zip\n",
        "!rm nature_12K.zip\n",
        "print(\"Extracted the dataset\");"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XHJLEmx47x_f",
        "outputId": "65179a86-0385-4747-a93b-f580a8222836"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mee21s125\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "!pip install wandb -qU\n",
        "import wandb\n",
        "wandb.login(key='2b25045507d6a89b66edf89be892f3687346ed10')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3y_ZfeulNECU"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "import os\n",
        "from glob import glob\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "import time\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "\n",
        "\n",
        "\n",
        "# Dataset Class for Setting up the data loading process\n",
        "class PreProcessDataset(Dataset):\n",
        "    def __init__(self, root_dir, image_size, mode = 'train', augument = 'True'):\n",
        "        self.root_dir = root_dir;\n",
        "        self.mode = mode;\n",
        "        self.augument = augument;\n",
        "        self.size = image_size;\n",
        "        self.prepareDataset();\n",
        "        self.imageTransform();\n",
        "\n",
        "    def prepareDataset(self):\n",
        "        self.files = [];\n",
        "        self.labels = [];\n",
        "        self.classes = [];\n",
        "\n",
        "        directory_path = os.path.join(self.root_dir, 'train');\n",
        "        folders = sorted(os.listdir(directory_path));\n",
        "\n",
        "        for i in folders:\n",
        "              if i[0]!= \".\":\n",
        "                self.classes.append(i);\n",
        "        print(\"Classes:\",self.classes);\n",
        "\n",
        "        if self.mode == 'train':\n",
        "            for i in range(len(self.classes)):\n",
        "                files = glob(os.path.join(directory_path, self.classes[i], '*.jpg'));\n",
        "                self.labels += [i]*len(files);\n",
        "                self.files += files;\n",
        "\n",
        "        elif self.mode == 'test':\n",
        "            directory_path = os.path.join(self.root_dir, 'val');\n",
        "            for i in range(len(self.classes)):\n",
        "                files = glob(os.path.join(directory_path, self.classes[i], '*.jpg'));\n",
        "                self.labels += [i]*len(files)\n",
        "                self.files += files\n",
        "        else:\n",
        "            print(\"Invalid Mode\");\n",
        "            return None\n",
        "\n",
        "    def imageTransform(self):\n",
        "      if (self.augument):\n",
        "        self.transform = transforms.Compose([\n",
        "            transforms.RandomRotation(30),\n",
        "            #transforms.RandomResizedCrop(self.size),\n",
        "            transforms.CenterCrop(226),\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.Resize((256,256)),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "        ]);\n",
        "      else:\n",
        "        self.transform = transforms.Compose([transforms.RandomResizedCrop(self.size),transforms.ToTensor()]);\n",
        "\n",
        "        # self.transforms = transforms.Compose([\n",
        "        #     transforms.RandomRotation(30),\n",
        "        #     transforms.RandomResizedCrop((256,256)),\n",
        "        #     transforms.RandomHorizontalFlip(),\n",
        "        #     transforms.ToTensor(),\n",
        "        #     transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "        #      transforms.Normalize([0.2356, 0.2300, 0.1948], [0.1096, 0.1055, 0.1075])\n",
        "        # ]);\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        img = Image.open(self.files[index]).convert('RGB');\n",
        "        img = self.transform(img);\n",
        "        label = self.labels[index];\n",
        "        label = torch.tensor(label, dtype = torch.long);\n",
        "        return img, label;\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.files);\n",
        "\n",
        "class convolutionNN(torch.nn.Module):\n",
        "    def __init__(self, image_size, num_input, num_output, filter_organization, batch_norm, num_layers, num_filters, filter_size, maxpool_size, dropout, activation, num_dense_neurons):\n",
        "        super(convolutionNN,self).__init__();\n",
        "        self.image_size = image_size;\n",
        "        self.num_input = num_input;\n",
        "        self.num_classes = num_output;\n",
        "        self.filter_organization = filter_organization;\n",
        "        self.batch_norm = batch_norm;\n",
        "        self.num_layers = num_layers;\n",
        "        self.num_filters = num_filters;\n",
        "        self.filter_size = filter_size;\n",
        "        self.maxpool_size = maxpool_size;\n",
        "        self.dropout = dropout;\n",
        "        self.num_dense_neurons = num_dense_neurons;\n",
        "\n",
        "        if activation == 'ReLU':\n",
        "          self.activation = torch.nn.ReLU;\n",
        "        if activation == 'GELU':\n",
        "          self.activation = torch.nn.GELU;\n",
        "        if activation == \"SiLU\":\n",
        "          self.activation = torch.nn.SiLU;\n",
        "        if activation == \"Mish\":\n",
        "          self.activation = torch.nn.Mish;\n",
        "        if activation == 'LeakyReLU':\n",
        "          self.activation = torch.nn.LeakyReLU;\n",
        "\n",
        "        self.filter_padding = 1;\n",
        "        self.filter_stride = 1;\n",
        "        self.maxpool_stride = 2;\n",
        "        self.layers = torch.nn.ModuleList();\n",
        "        num_filters_used = [self.num_filters];\n",
        "\n",
        "\n",
        "        for i in range(self.num_layers):\n",
        "          #Since filter sizes are reducing significantly\n",
        "          self.filter_padding = (self.filter_size-1)//2;\n",
        "          self.convolutionBlock();\n",
        "          self.num_input = self.num_filters;\n",
        "          if(self.filter_organization == 'half'):\n",
        "            self.num_filters = self.num_filters//2;\n",
        "            num_filters_used.append(self.num_filters);\n",
        "          if(self.filter_organization == 'same'):\n",
        "            self.num_filters = self.num_filters;\n",
        "            num_filters_used.append(self.num_filters);\n",
        "          if(self.filter_organization == 'double'):\n",
        "            self.num_filters = self.num_filters*2;\n",
        "            num_filters_used.append(self.num_filters);\n",
        "\n",
        "        final_dim = self.computeInputSizeToDense();\n",
        "        conv_output_dim = final_dim * final_dim * num_filters_used[-2];\n",
        "        print(final_dim, conv_output_dim ,num_filters_used);\n",
        "\n",
        "\n",
        "        self.FCN = torch.nn.Sequential(\n",
        "            torch.nn.Flatten(),\n",
        "            torch.nn.Linear(conv_output_dim, self.num_dense_neurons),\n",
        "            self.activation(),\n",
        "            torch.nn.Dropout(self.dropout),\n",
        "            torch.nn.Linear(self.num_dense_neurons, self.num_classes)\n",
        "            );\n",
        "\n",
        "    def convolutionBlock(self):\n",
        "        self.layers.append(torch.nn.Conv2d(self.num_input,self.num_filters, self.filter_size, padding = self.filter_padding));\n",
        "        self.layers.append(self.activation());\n",
        "        self.layers.append(torch.nn.MaxPool2d(self.maxpool_size, stride = self.maxpool_stride));\n",
        "        if(self.batch_norm == True):\n",
        "          self.layers.append(torch.nn.BatchNorm2d(self.num_filters));\n",
        "\n",
        "    def computeInputSizeToDense(self):\n",
        "        input = self.image_size;\n",
        "        #print(\"input:\",input)\n",
        "        for i in range(self.num_layers):\n",
        "          #print(\"Padding:\", self.filter_padding);\n",
        "          conv_output = np.ceil(float(input - self.filter_size + (2*self.filter_padding))/self.filter_stride) + 1;\n",
        "          #print(\"Conv output Dim:\",conv_output);\n",
        "          maxpool_output = np.floor(float(conv_output - self.maxpool_size)/self.maxpool_stride) + 1;\n",
        "          #print(\"maxpool_output:\",maxpool_output);\n",
        "          input = maxpool_output;\n",
        "        return int(maxpool_output);\n",
        "\n",
        "    def forward(self,x):\n",
        "      #print(\"Input:\", self.image_size, \"x.size():\", x.size())\n",
        "      for layer in self.layers:\n",
        "        x = layer(x);\n",
        "        #print(\"layer: \", layer, \"x.size():\", x.size())\n",
        "      x = self.FCN(x);\n",
        "      return torch.nn.functional.softmax(x,dim=1);\n",
        "\n",
        "\n",
        "\n",
        "def train(model, dataset, optimizer, criterion, device):\n",
        "\n",
        "    epoch_loss = 0\n",
        "    epoch_correct_predictions = 0\n",
        "    epoch_total_samples = 0\n",
        "    model.train();\n",
        "    for i, (images,labels) in enumerate(dataset):\n",
        "        #setting gradients to zero again to prevent any incorrect calculation\n",
        "        optimizer.zero_grad();\n",
        "        #loading the data accordingly\n",
        "        #images, labels = next(iter(dataset));\n",
        "        images, labels = images.to(device), labels.to(device);\n",
        "        #forward pass\n",
        "        predicted = model.forward(images);\n",
        "        #calculate loss\n",
        "        loss = criterion(predicted,labels);\n",
        "        #gradient descent\n",
        "        loss.backward();\n",
        "        #optimizer updates the parameters\n",
        "        optimizer.step();\n",
        "        #print(\"Lenth labels:\",len(labels));\n",
        "        _, predicted_labels = torch.max(predicted, 1);\n",
        "        correct_predictions = (predicted_labels == labels).sum().item();\n",
        "        batch_accuracy = correct_predictions / len(labels);\n",
        "\n",
        "        # Accumulate loss and accuracy for the epoch\n",
        "        epoch_loss += loss.item() * len(labels);\n",
        "        epoch_correct_predictions += correct_predictions;\n",
        "        epoch_total_samples += len(labels);\n",
        "\n",
        "    # Calculate average loss and accuracy for the epoch\n",
        "    epoch_loss /= epoch_total_samples;\n",
        "    epoch_accuracy = epoch_correct_predictions / epoch_total_samples;\n",
        "\n",
        "    return epoch_loss, epoch_accuracy;\n",
        "\n",
        "\n",
        "def validate(model, dataset, criterion, device):\n",
        "\n",
        "    epoch_loss = 0\n",
        "    epoch_correct_predictions = 0\n",
        "    epoch_total_samples = 0\n",
        "    model.train();\n",
        "    for i, (images,labels) in enumerate(dataset):\n",
        "        #loading the data accordingly\n",
        "        #images, labels = next(iter(dataset));\n",
        "        images, labels = images.to(device), labels.to(device);\n",
        "        #forward pass\n",
        "        predicted = model.forward(images);\n",
        "        #calculate loss\n",
        "        loss = criterion(predicted,labels);\n",
        "        #print(\"Lenth labels:\",len(labels));\n",
        "\n",
        "        _, predicted_labels = torch.max(predicted, 1);\n",
        "        correct_predictions = (predicted_labels == labels).sum().item();\n",
        "        batch_accuracy = correct_predictions / len(labels);\n",
        "\n",
        "        # Accumulate loss and accuracy for the epoch\n",
        "        epoch_loss += loss.item() * len(labels);\n",
        "        epoch_correct_predictions += correct_predictions;\n",
        "        epoch_total_samples += len(labels);\n",
        "\n",
        "    # Calculate average loss and accuracy for the epoch\n",
        "    epoch_loss /= epoch_total_samples;\n",
        "    epoch_accuracy = epoch_correct_predictions / epoch_total_samples;\n",
        "\n",
        "    return epoch_loss, epoch_accuracy;\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 503
        },
        "id": "078mPylnJ6Dh",
        "outputId": "6b16bccc-0121-4801-c507-84acaffc566c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Create sweep with ID: ofmdawlk\n",
            "Sweep URL: https://wandb.ai/ee21s125/EE21S125_DL_A2/sweeps/ofmdawlk\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: eucr52zs with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: Mish\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_normalization: True\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_augmentation: False\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tfilter_organization: half\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 1e-05\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_dense_neurons: 256\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_epochs: 15\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_filters: 128\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: NAdam\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.0005\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.16.6"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20240410_133832-eucr52zs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/ee21s125/EE21S125_DL_A2/runs/eucr52zs' target=\"_blank\">woven-sweep-1</a></strong> to <a href='https://wandb.ai/ee21s125/EE21S125_DL_A2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/ee21s125/EE21S125_DL_A2/sweeps/ofmdawlk' target=\"_blank\">https://wandb.ai/ee21s125/EE21S125_DL_A2/sweeps/ofmdawlk</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/ee21s125/EE21S125_DL_A2' target=\"_blank\">https://wandb.ai/ee21s125/EE21S125_DL_A2</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/ee21s125/EE21S125_DL_A2/sweeps/ofmdawlk' target=\"_blank\">https://wandb.ai/ee21s125/EE21S125_DL_A2/sweeps/ofmdawlk</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/ee21s125/EE21S125_DL_A2/runs/eucr52zs' target=\"_blank\">https://wandb.ai/ee21s125/EE21S125_DL_A2/runs/eucr52zs</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classes: ['Amphibia', 'Animalia', 'Arachnida', 'Aves', 'Fungi', 'Insecta', 'Mammalia', 'Mollusca', 'Plantae', 'Reptilia']\n",
            "Device: cuda\n",
            "input: 256\n",
            "8 512 [128, 64, 32, 16, 8, 4]\n",
            "Epoch Time Taken: 233.1797194480896\n",
            "Training Accuracy: 0.1532691586448306  Training Loss: 2.2815413496496975  Validation Accuracy: 0.17527190898862358  Validate Loss: 2.2675692230958555  Epoch: 1\n"
          ]
        }
      ],
      "source": [
        "def main():\n",
        "    wandb.init(project='EE21S125_DL_A2')\n",
        "    #Preprocessing Parameters\n",
        "    augument = wandb.config.data_augmentation;\n",
        "    num_dense_neurons = wandb.config.num_dense_neurons;\n",
        "    learning_rate = wandb.config.learning_rate;\n",
        "    dropout = wandb.config.dropout;\n",
        "    activation = wandb.config.activation;\n",
        "    num_filters = wandb.config.num_filters;\n",
        "    filter_organization = wandb.config.filter_organization;\n",
        "    batch_norm = wandb.config.batch_normalization;\n",
        "    num_epochs = wandb.config.num_epochs;\n",
        "    weight_decay = wandb.config.weight_decay;\n",
        "    optimizer = wandb.config.optimizer;\n",
        "\n",
        "    # augument = False;\n",
        "    # num_dense_neurons = 256;\n",
        "    # learning_rate = 0.001;\n",
        "    # dropout = 0.3;\n",
        "    # activation = 'ReLU';\n",
        "    # num_filters = 32;\n",
        "    # filter_organization = 'double';\n",
        "    # batch_norm = True;\n",
        "    # num_epochs = 5;\n",
        "    # weight_decay = 0;\n",
        "    # optimizer = 'NAdam'\n",
        "\n",
        "\n",
        "    dataset_directory = 'inaturalist_12K';\n",
        "    image_size = 256;\n",
        "    batch_size = 10;\n",
        "    num_input = 3;\n",
        "    num_output = 10;\n",
        "    num_layers = 5;\n",
        "    filter_size = 3;\n",
        "    maxpool_size = 2;\n",
        "    mode = 'train';\n",
        "\n",
        "    wandb.run.name = (\"Aug_\"+str(augument)+\n",
        "                      \"_bn_\"+str(batch_norm)+\n",
        "                      \"_fcn_\"+str(num_dense_neurons)+\n",
        "                      \"_do_\"+str(dropout)+\n",
        "                      \"_act_\"+str(activation)+\n",
        "                      \"_nf_\"+str(num_filters)+\n",
        "                      \"_fo_\"+str(filter_organization)+\n",
        "                      \"_lr_\"+str(learning_rate)\n",
        "                      );\n",
        "\n",
        "    training_set = PreProcessDataset(dataset_directory, image_size, mode, augument);\n",
        "    train_size = int(0.8*len(training_set));\n",
        "    validate_size = len(training_set) - train_size;\n",
        "    train_dataset, validate_dataset = torch.utils.data.random_split(training_set, [train_size, validate_size]);\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0);\n",
        "    validate_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0);\n",
        "\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu');\n",
        "    print(\"Device:\", device);\n",
        "\n",
        "    # Creating an instance of the model\n",
        "    model = convolutionNN(image_size, num_input, num_output, filter_organization, batch_norm, num_layers, num_filters, filter_size, maxpool_size, dropout, activation, num_dense_neurons).to(device);\n",
        "\n",
        "    criterion = torch.nn.CrossEntropyLoss();\n",
        "    if optimizer == 'NAdam':\n",
        "      optimizer=torch.optim.NAdam(model.parameters(),lr=learning_rate,weight_decay=weight_decay);\n",
        "      anneal = CosineAnnealingLR(optimizer, T_max=num_epochs/2, eta_min = 0.0001);\n",
        "    elif optimizer == 'SGD':\n",
        "      optimizer=torch.optim.SGD(model.parameters(),lr=learning_rate,weight_decay=weight_decay);\n",
        "      anneal = CosineAnnealingLR(optimizer, T_max=num_epochs/2, eta_min = 0.0001)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "      start_time = time.time();\n",
        "      train_loss,train_accuracy = train(model,train_loader,optimizer,criterion,device);\n",
        "      validate_loss,validate_accuracy = validate(model,validate_loader,criterion,device);\n",
        "      anneal.step();\n",
        "      end_time = time.time();\n",
        "      elapsed_time = end_time - start_time;\n",
        "\n",
        "      print(\"Epoch Time Taken:\", elapsed_time);\n",
        "      print(\"Training Accuracy:\", train_accuracy,\" Training Loss:\", train_loss, \" Validation Accuracy:\", validate_accuracy, \" Validate Loss:\", validate_loss,\" Epoch:\", epoch +1);\n",
        "      wandb.log({'train_loss': train_loss, 'train_accuracy':train_accuracy, 'validate_loss': validate_loss, 'validate_accuracy': validate_accuracy, 'epoch':epoch + 1})\n",
        "    wandb.finish();\n",
        "    print(\"TRAINING AND VALIDATION COMPLETE\");\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "### Used for checking the transform value ####\n",
        "    # trainloader = DataLoader(trainset, batch_size=2, shuffle=True, num_workers=0);\n",
        "    # print(\"Trainloader:\", trainloader);\n",
        "    # #data_loader = torch.utils.data.DataLoader(trainset.__getitem__(), batch_size=100, shuffle=False)\n",
        "    # mean = torch.zeros(3)\n",
        "    # std = torch.zeros(3)\n",
        "    # num_samples = 0\n",
        "\n",
        "    # for inputs, _ in trainloader:\n",
        "    #     batch_size = inputs.size(0)\n",
        "    #     num_samples += batch_size\n",
        "    #     # Compute mean across batch and channels\n",
        "    #     mean += torch.mean(inputs, dim=(0, 2, 3))\n",
        "    #     # Compute std across batch and channels\n",
        "    #     std += torch.std(inputs, dim=(0, 2, 3))\n",
        "\n",
        "    # mean /= num_samples\n",
        "    # std /= num_samples\n",
        "\n",
        "    # print(\"Mean:\", mean)\n",
        "    # print(\"Standard Deviation:\", std)\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    sweep_config = {\n",
        "                    'method': 'random',  # Choose 'grid', 'random', 'bayes', etc.\n",
        "                    'metric': {\n",
        "                                'name': 'validate_accuracy',\n",
        "                                'goal': 'maximize'\n",
        "                              },\n",
        "                    'parameters': {\n",
        "                        'num_filters': {'values': [32, 64, 128]},\n",
        "                        'activation': {'values': ['ReLU', 'GELU', 'SiLU', 'Mish','LeakyReLU']},\n",
        "                        'filter_organization': {'values': ['same', 'double', 'half']},\n",
        "                        'data_augmentation': {'values': [True, False]},\n",
        "                        'batch_normalization': {'values': [True, False]},\n",
        "                        'num_dense_neurons':{'values': [128,256]},\n",
        "                        'dropout': {'values': [0.2, 0.3]},\n",
        "                        'learning_rate': {'values': [1e-4,1e-5]},\n",
        "                        'weight_decay': {'values': [0, 0.0005, 0.5]},\n",
        "                        'optimizer': {'values': ['NAdam','SGD']},\n",
        "                        'num_epochs': {'values': [15]}\n",
        "\n",
        "                    }\n",
        "                  }\n",
        "    sweep_id = wandb.sweep(sweep= sweep_config, project='EE21S125_DL_A2');\n",
        "    wandb.agent(sweep_id, function = main,count=25);\n",
        "    #main();\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}